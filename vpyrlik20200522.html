<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>DW Mock presentations</title>
    <meta charset="utf-8" />
    <meta name="author" content="Vladimir Pyrlik" />
    <meta name="date" content="2020-05-22" />
    <link rel="stylesheet" href="libs\main.css" type="text/css" />
    <link rel="stylesheet" href="libs\fonts.css" type="text/css" />
    <link rel="stylesheet" href="libs\animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# DW Mock presentations
## Ultra-high Dimensional Copulas:</br>Estimation &amp; Application
### Vladimir Pyrlik
### May 22, 2020

---

class: section, center, middle, animated, flipInY
##Introduction
#Copulas &amp; High Dimensionality

---
class: animated, fadeIn
##Copulas &amp; High Dimensionality

- **Copulas**: a convenient approach to generate flexible multivariate distributions
 
- **Dimensionality Curse**: in HD, either the existing frameworks are not flexible enough, or estimation is very hard to handle

--

- **Possible solutions**: dimensionality breakdown, structural restrictions, *shrinkage*

---
class: animated, fadeIn
## Presentation Outline

- Copulas: **the briefest introduction**

--

- **Paper 1**: Shrinkage for Gaussian and t Copulas in UHD

  - Methodology &amp; **main results**

  - **Empirical example**: large portfolio allocation

--

- **Paper 2**: Copula-based Combination of (Ultra-)many Forecasts *(proposal)*

---
class: section, center, middle, animated, flipInX
##The briefest introduction into
#Copulas

---
class: animated, fadeIn
##What are copulas?

- Copula is a multivariate CDF with `\(U[0,1]\)` marginals

--

## Why are copulas important?

- **Sklar's theorem**: `\(F_Y(y_1,...y_p)=C_Y(F_1(y_1),...F_p(y_p))\)`

--

- **The converse holds, too**: borrow a copula of one distribution, feed an arbitrary set of margins to it, and obtain a new multivariate distribution.

---
class: section, center, middle, animated, flipInY
## Paper 1
#Shrinkage for Gaussian and t Copulas
#in Ultra-high Dimensions

---
class: animated, fadeIn
## What we do

- consider Gaussian and t copulas in (U)HD

- adopt and evaluate the performance of shrinkage estimators of large covariance matrices via a simulation study

- apply the UHD t copula to improve large portfolio allocation in the stock market

---
class: animated, fadeIn
##Outline

- Gaussian and t copulas: motivation and properties

- Shrinkage estimators

- Simulation study design and results

- Empirical example: large portfolio allocation


---
class: animated, fadeIn
###Popular classes of copulas

##Archimedean copulas

.gb[Pro] Have analytical forms and well established properties

.gb[Pro] Easily extendable to HD

--

.rb[Con] Very rigid: parameter is always low dimensional

---
class: animated, fadeIn
###Popular classes of copulas
##Pair copula constructions aka Vines

.gb[Pro] The most flexible copula structure there can be

--

.rb[Con] Requires structural assumptions on the data

.rb[Con] HD is very hard to handle

---
class: animated, fadeIn
###Popular classes of copulas
##Elliptical copulas

.gb[Pro] Extendable to and remain flexible in HD

.rb[Con] Traditional estimators fail in HD

--

.blank[.]

- Most popular members: **Gaussian &amp; t copulas**

- Used in a **vast variety of applications**

- **HD is appealing** (many variables or short samples)

---
class: animated, fadeIn
###Definition &amp; important properties
##General notation

Consider a *p*-dimensional r.v. `\(Y=(Y_1,...Y_p)'\)` with joint CDF `\(F_Y(y_1,...y_p;\theta)\)` and marginal CDFs `\(\{F_i(y_i;\theta)\}_{i=1,...p}\)`,

--

and a transformed r.v. `\(U=(U_1,...U_p)'\)`, s.t. `\(U_i=F_i(Y_i;\theta).\)`

--

The joint CDF `\(C_Y(u;\theta)\)` of `\(U\)` is called **the copula function of `\(F_Y\)`**,

--

and its density `\(c_Y(u;\theta)\)` is **the copula density function**.

---
class: animated, fadeIn
###Definition &amp; important properties
##Gaussian copula

`$$Y\sim\mathcal{N}(\mathbb{O}_p;P),\;\text{and}\;U_i=\Phi_{0,1}(Y_i).$$`

--

The joint CDF of `\(U\)` is **the Gaussian copula**:

`$$C_{\mathcal{N}}(u;P)=F_{\mathcal{N(\mathbb{O}_p,P)}}(\phi(u);P),$$`

with the **copula density**

`$$\log c_\mathcal{N}(u;P)=-\frac{1}{2}\log|P|-\frac{1}{2}\phi'(u)\cdot(P^{-1}-I_p)\cdot\phi(u),$$`

`$$\phi(u)=\big(\Phi_{0,1}^{-1}(u_1),...,\Phi_{0,1}^{-1}(u_p)\big)'.$$`

---
class: animated, fadeIn
###Measures of dependence
##Gaussian copula

- **Kendall's rank correlation**: `\(\tau_{ij}=\frac{2}{\pi}\text{asin}(P_{ij})\)`.

- **Spearman's rank correlation**: `\(\text{Corr}(U)=\frac{6}{\pi}\text{asin}\left(\frac{P}{2}\right)\)`.

--

- **Approx. Spearman's rank correlation**: `\(\text{Corr}(U)\approx P\)`.

--

- **Underlying r.v. *Y* correlation**: `\(\text{Corr(Y)}=P\)`.

---
class: animated, fadeIn
###Definition &amp; important properties
##t copula

`$$Y\sim MVT(P,\nu),\;\text{and}\;U_i=t_\nu(Y_i;\nu).$$`

--

### Measures of dependence

- **Kendall's rank correlation**: `\(\tau_{ij}=\frac{2}{\pi}\text{asin}(P_{ij})\)`.

--

- **Approx. Spearman's rank correlation**: `\(\text{Corr}(U)\approx P\)`.

--

- **Underlying r.v. *Y* correlation**: `\(\text{Corr(Y)}=P\)`.

---
class: animated, flipInX
###Why t copula?
##Tail dependence

.center[![](stuff/snp500_top3_logr.png)]

---
class: animated, fadeIn
##Approaches to estimation
###Main idea
Given the DGP

`$$X\sim F_X=C_Y(F_{X_1}(x_1;\theta_1),...F_{X_p}(x_p;\theta_p);\Theta_C)$$`

--

the copula-related part and the marginals can be estimated separately:

1. Estimate the marginals `\(\{\hat F_{X_i}(x)\}_{i=1,...p}\)`

--

2. Use the **pseudo-data** `\(U_i=\hat F_{X_i}(X_i)\)` to estimate `\(C_Y\)`.

---
class: animated, fadeIn
###Approaches to estimation
##Full MLE

--

Jointly estimates the whole distribution of *X*, **disregarding the copula construction of `\(F_X\)`**.

.gb[Pro] The efficient estimator

--

.rb[Con] Might be impractical even in LD

.rb[Con] Crucially impractical in moderate and HD

---
class: animated, fadeIn
###Approaches to estimation
##Maximum pseudo-likelihood estimation (MPLE)

Consider `\(C_Y\)` as the joint distribution of `\(U\)` and apply MLE.

--

.gb[Pro] Numerically, very close to FMLE, if `\(\hat F_{X_i}\)`s are good.

.rb[Con] Impractical in HD

---
class: animated, fadeIn
###Approaches to estimation
##Method-of-moments-like estimators

Use the measures of dependence to estimate *(some of)* the parameters of `\(C_Y\)`.

--

.gb[Pro] Very practical, even in HD

.rb[Con] Not well-conditioned estimates, sometimes even in LD

--

**Solution**: large covariance matrix estimators can be employed to estimate the matrix parameters of the copulas

--

.blank[.]

.rmk[MPLE needs to be used to estimate the remaining parameter of t copula] 

---
class: animated, fadeIn
###The intuition of 
##Large covariance matrices shrinkage estimators

.center[![](stuff/eigenval_distr.png)]

---
class: animated, fadeIn
###The variety of
##Large covariance matrices shrinkage estimators

.left[.rmk[Ledoit, O., &amp; Wolf, M. (2004). Honey, I shrunk the sample covariance matrix. The Journal of Portfolio Management, 30(4), 110-119.]]

.left[.rmk[Ledoit, O., &amp; Wolf, M. (2004). A well-conditioned estimator for large-dimensional covariance matrices. Journal of multivariate analysis, 88(2), 365-411.]]

--

.left[.rmk[Ledoit, O., &amp; Wolf, M. (2012). Nonlinear shrinkage estimation of large-dimensional covariance matrices. The Annals of Statistics, 40(2), 1024-1060.]]

.left[.rmk[Ledoit, O., &amp; Wolf, M. (2017). Numerical implementation of the QuEST function. Computational Statistics &amp; Data Analysis, 115, 199-223.]]

.left[.rmk[Ledoit, O., &amp; Wolf, M. (2018). Analytical nonlinear shrinkage of large-dimensional covariance matrices. University of Zurich, Department of Economics, Working Paper, (264).]]

---
class: animated, fadeIn
###A rough sketch of
##The simulation study

Given *p*, *n*, *P*, `\(\{F_{X_i}\}_{i=1,...p}\)`, `\(C_Y(u;P)\)` we find and compare `\(\hat P\)`s:

--

1. Simulate data `\(X\)` from `\(C_Y(\{F_{X_i}(x)\}_i;P)\)` and switch to the pseudo-data `\(U_i=\hat F_{X_i}(X_i)\)`.

--

2. Estimate `\(P\)` from a variety of `\(\text{Corr}(U)\)` related measures.

--

3. Evaluate the quality of estimates.

--

4. Repeat 1 - 3 sufficient number of times.

---
class: animated, fadeIn
###Some details of
##The simulation study

###The DGP and data

- **Copulas**: Gaussian and t

--

- **Dimensions**: `\(p\in\{10,100,1000\}\)`

--

- **Dimensionality**: `\(\frac{1}{20}\le\frac{p}{n}\le20\)`

--

- **Matrix parameter**: identity or a non-sparse correlation

--

.rmk[*Other*: skew-t marginals, d.f.=8 for t copula, B&gt;1000]

---
class: animated, fadeIn
###Some details of
##The simulation study

###The traditional estimators

- Sample analog of Kendall's rank correlation

- Sample analog of approx. Spearman's rank correlation

--

###Suggested alternative estimators

- Linear and non-linear shrinkage estimators of pseudo-observations correlation

--

.rmk[for t copula, the d.f. parameter is estimated via MPLE]

---
class: animated, fadeIn
###Some details of
##The simulation study

###Estimates quality criteria

- **Sanity check**: positive-definiteness of `\(\hat P\)`

--

- **Closeness of the parameters values**: Euclidean loss,

`$$EL(P,\hat P)=||\text{vech}(P-\hat P)||_E^2$$`

--

- **Closeness of the copulas**: Kullback - Leibler IC,

`$$KLIC_{C_{\hat P}|C_P}=\mathbb{E}_{C_P}[\log c_P(u)-\log c_{\hat P}(u)]$$`

---
class: animated, fadeIn
##Main results
###Well-conditioned estimates

- The traditional estimators are only positive-definite under LD.

- Shrinkage-based estimators guarantee positive-definiteness.

---
class: animated, fadeIn
##Main results
###Distance measures

- Shrinkage-based estimators generally outperform the traditional ones, very significantly in HD

--

- Non-linear shrinkage tends to outperform the linear one

--

- Few settings where the linear shrinkage is better

  - Not very dispersed true eigenvalues
  
  - Sparse (identity) correlation matrix &amp; short samples 

--

  - .rmk[even then the gain of LSh is minimal]

---
class: animated, fadeIn
##Main results
###A typical performance slice #1

.center[The "winning" KLIC: p=100, arbitrary P, Gaussian copula]

.center[![](stuff/best_estimators_7_KLIC.png)]

---
class: animated, fadeIn
##Main results
###A typical performance slice #2

.center[The "winning" KLIC: p=1000, identity P, t copula]

.center[![](stuff/best_estimators_10_KLIC2.png)]

---
class: section, middle, center, animated, flipInY
##UHD t copula application for
#Large portfolio allocation
###Empirical example

---
class: animated, fadeIn
##What we do
We apply t copula shrinkage estimation to allocate large portfolios of stocks and compare their performance with portfolio choices based on the traditional  estimators.

--

##Outline

 - **Copulas &amp; portfolios**: motivation and intuition
 
 - **Why UHD?** Data description
 
 - **Modeling technique**
 
 - **Main results and discussion**

---
class: animated, fadeIn
##Copulas &amp; portfolios

- Portfolio allocation is **one of the most popular applications** for the models of joint distribution of assets prices

--

- Portfolios' performance crucially depends on the **ability of the models to capture essential properties** of the data

--

  - Copulas allow to create **flexible models**
  
  - **Tail dependence** proved to be of dramatic importance

---
class: animated, fadeIn
###Data description
##Why UHD?

- We use the listing of Wilshire 5000 index and obtain data on 3600+ assets from CRSP

--

- Each portfolio contains .bb[p=2500 assets] chosen randomly

--

- The univariate models of returns dynamics are simple

- Only 6 months of 2017 are used for estimation, .bb[n=120 obs]

--

- Thus, the dimensionality is .bb[p/n &gt; 20]

---
class: animated, fadeIn
##Modeling technique

###1. The timeline

###2. Univariate asset's returns dynamics modeling

###3. Joint distribution of the prices modeling and prediction

###4. Portfolio allocation

###5. Portfolio performance measurement

---
class: animated, fadeIn
##Modeling technique
###1. The timeline
 
 - January - June 2017: training period

--

 - end of June, 2017: portfolio allocation

--

 - July - September, 2017: portfolio lifetime

--

 - end of September, 2017: performance measurement

---
class: animated, fadeIn
##Modeling technique
###2. The univariate modeling

- The assets prices dynamics are stationarized by taking the daily log-returns

- ARMA (up to 5,5) is used to filter out the conditional mean

  - .rmk[the best ARMA: minimal AIC among those without residual autocorrelation]

- **Serially uncorrelated residuals are extracted** 

---
class: animated, fadeIn
##Modeling technique
###3a. Joint distribution modeling

**4 estimates of the joint distribution of the residual returns**:

1. MVN (basic sample estimator)

--

2. t copula over ECDFs:
 
--

 - sample estimator
 
 - linear shrinkage estimator
 
 - non-linear shrinkage estimator

---
class: animated, fadeIn
##Modeling technique
###3b. Joint distribution prediction

**To predict the distribution of the assets prices out-of-sample, Monte-Carlo is employed**

1. Joint dynamics of the residual returns is simulated from MVN or copula model

2. Log-returns dynamics is restored accordingly

3. The original prices dynamics is calculated

---
class: animated, fadeIn
##Modeling technique
###4. Portfolio allocation

- *Static portfolio allocation, no t.c. or other frictions*

--

- **The benchmark**: equally weighted portfolio

--

- **Model-based portfolios**: Sharpe ratio maximizers

--

- .rmk[Numerically, the allocation problem is a disaster. Hence, MC is employed, again. A choice among pre-determined portfolio structures is performed.]

---
class: animated, fadeIn
##Modeling technique
###5. Portfolio performance measurement

- We track the actual dynamics of the portfolios value over their lifetime period according to the actual assets prices

--

- We measure **the actual return over the whole lifetime**

--

- We measure **maximum drop down of the current value within the lifetime**

--

- We compare the performance of the model-based choices to the equally weighted portfolio

---
class: animated, flipInX
##Main results
###Lifetime portfolios value dynamic. Example #1

.center[![](stuff/return1.png)]

---
class: animated, flipInY
##Main results
###Lifetime portfolios value dynamic. Example #2
.center[![](stuff/return4.png)]

---
class: animated, bounceIn
##Main results
###Portfolios performance overview
.center[![](stuff/returns.png) .blank[..........] ![](stuff/downfalls.png)]

---
class: section, middle, animated, flipInX
###Paper 1
##Discussion and Further Research

---
class: animated, fadeIn
##Results &amp; further research

###1. Shrinkage is a powerful tool of estimation for copulas

.bb[Further in this paper:] other estimators of matrix parameters

--

.bb[Another work:] extended copulas (skewed versions)

--

###2. HD Copula modeling is beneficial in portfolio allocation

.bb[Another work:] a profound dynamic model of joint distribution of assets prices based on copula and shrinkage

--

.bb[Another work:] copula-based forecast combination technique

---
class: section, center, middle, animated, flipInY
##Paper 2
#Copula-based Combination
#of Ultra-many Forecasts
###(Proposal)

---
class: animated, fadeIn
###Copula-based Combination of Ultra-many Forecasts
##Motivation

- Forecast combination is similar to the portfolio allocation.

--

- When the **number of alternative predictors is large** and they belong to a class of similar predictors, the forecast errors are likely to be with a certain degree of tail dependence.

--

- Validation must be based on recent information, hence, **the samples need to be short**.

--

- **HD estimators will allow to use more predictors** and construct more accurate forecasts.

--

- **Copula-based models are likely to improve the performance of the combined forecast**.

---
class: section, animated, bounceIn
##Thank you!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false,
"slideNumberFormat": "%current%/%total%",
"highlightLines": true,
"ratio": "8:5"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
